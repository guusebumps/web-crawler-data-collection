# Web Crawler

A simple web crawler built with Go to scrape specific data from websites.

## Features
- Scrapes specified elements (e.g., titles, links).
- Lightweight and fast.
- Easy to extend.

## Installation
1. Clone this repository:
   ```bash
   git clone https://github.com/guusebumps/web-crawler-data-collection.git
   cd web-crawler
   ```
2. Install dependencies:
   ```bash
   go mod tidy
   ```
3. Run the crawler:
   ```bash
   go run main.go
   ```

## Dependencies
- [Colly](https://github.com/gocolly/colly)
